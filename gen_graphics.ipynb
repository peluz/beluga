{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f829ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pickle\n",
    "from scipy.stats import hmean\n",
    "from scipy.stats import kendalltau, pearsonr\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5457e88",
   "metadata": {},
   "source": [
    "## Fine-grained results image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3dcb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(task):\n",
    "    results = pd.read_csv(f\"./data/{task}/results_fine.csv\")\n",
    "    results[\"method\"] = results[\"method\"].str.replace(\"default\", \"Vanilla\")\n",
    "    results[\"method\"] = results[\"method\"].str.replace(\"l2\", \"L2\")\n",
    "    results[\"method\"] = results[\"method\"].str.replace(\"dropout\", \"Dropout\")\n",
    "    results[\"method\"] = results[\"method\"].str.replace(\"freeze\", \"LP\")\n",
    "    results[\"method\"] = results[\"method\"].str.replace(\"lp-ft\", \"LP-FT\")\n",
    "    results[\"method\"] = results[\"method\"].str.replace(\"irm\", \"IRM\")\n",
    "    results[\"method\"] = results[\"method\"].str.replace(\"dro\", \"G-DRO\")\n",
    "    results[\"method\"] = results[\"method\"].str.replace(\"fish\", \"Fish\")\n",
    "    results = results.set_index([\"method\", \"config\", \"score\"])\n",
    "\n",
    "    results[\"avg\"] =  results.mean(axis=1)\n",
    "\n",
    "    cols = results.columns.tolist()\n",
    "\n",
    "    cols = [cols[-1]] + cols[0:-1]\n",
    "\n",
    "    results = results[cols]\n",
    "\n",
    "    n_funcs = len(results.select_dtypes(include=np.number).columns.tolist())\n",
    "\n",
    "    func_dic = pickle.load(open(f\"./data/{task}/func_dic.pkl\", \"rb\"))\n",
    "\n",
    "    capabilities = np.array([v[0] for v in func_dic.values()])\n",
    "\n",
    "    test_types = np.array([v[1] for v in func_dic.values()])\n",
    "\n",
    "    if task == \"qqp\": # Reorder to group the vocabulary functionalities\n",
    "        test_types[7], test_types[10] = test_types[10], test_types[7]\n",
    "        capabilities[7], capabilities[10] = capabilities[10], capabilities[7]\n",
    "        cols[8], cols[11] = cols[11], cols[8]\n",
    "        results = results[cols]\n",
    "\n",
    "\n",
    "    capabilities = np.concatenate([[\"avg\"], capabilities])\n",
    "\n",
    "    capabilities_idx = np.where(capabilities[:-1] != capabilities[1:])[0] +1\n",
    "\n",
    "    type_to_color = {\"mft\": \"b\", \"inv\": \"r\", \"dir\": \"g\"}\n",
    "\n",
    "    type_colors = [\"k\"] + [type_to_color[t] for t in test_types]\n",
    "\n",
    "    y_labels = [m if m != \"Vanilla\" else f\"{c}: Vanilla\" for  m, c, s in list(results[results.index.isin(['standard', \"seen\"], level=2)].index)]\n",
    "    \n",
    "    return results, y_labels, type_colors, capabilities_idx, n_funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85116ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_plot(results, score, ax):\n",
    "    sns.heatmap(results[results.index.isin(['standard', score], level=2)],\n",
    "    #             annot=True,\n",
    "                linewidths=1, ax = ax,\n",
    "                xticklabels=[\"Avg\"] + list(range(1, n_funcs)),\n",
    "                yticklabels = y_labels if score == \"seen\" else [],\n",
    "                vmin=0,\n",
    "                vmax=100,\n",
    "                cbar=False\n",
    "    #             fmt=\".0f\"\n",
    "               )\n",
    "    ax.set_xticks(capabilities_idx, minor=True)\n",
    "    ax.set_yticks([1, 9, 17], minor=True)\n",
    "#     ax.set_ylabel(\"Configuation, method\") if score == \"seen\" else ax.set_ylabel(\"\")\n",
    "    ax.set_ylabel(\"\")\n",
    "    ax.grid(True, which='minor', linewidth=.5, color=\"blue\")\n",
    "    for ticklabel, tickcolor in zip(ax.get_xticklabels(), type_colors):\n",
    "        ticklabel.set_color(tickcolor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a744c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 18})\n",
    "plt.rc('xtick', labelsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759e7bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(figsize=(32,24), ncols=5, nrows=3, gridspec_kw=dict(width_ratios=[1, 1, 1, 1, 0.05], wspace=0.1, hspace=0.1))\n",
    "for row, task in enumerate([\"sa\", \"qqp\", \"squad\"]):\n",
    "    results, y_labels, type_colors, capabilities_idx, n_funcs = get_results(task)\n",
    "    for col, score in enumerate([\"seen\", \"funcOut\", \"classOut\", \"aspectOut\"]):\n",
    "        create_plot(results, score, axs[row, col])\n",
    "    fig.colorbar(axs[0,0].collections[0], cax=axs[row, 4])\n",
    "fig.subplots_adjust(left=0, bottom=0, right=1, top=1, wspace=0, hspace=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6032c9f",
   "metadata": {},
   "source": [
    "## Agg-results table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fed3a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = [\"sa\", \"qqp\", \"squad\"]\n",
    "results = [pd.read_csv(f\"./data/{task}/results.csv\", sep=\"\\t\").dropna() for task in tasks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d8f730",
   "metadata": {},
   "outputs": [],
   "source": [
    "for result in results:\n",
    "    result[\"Seen\"] = hmean([result[\"Seen\"], result[\"iid score\"]])\n",
    "    result[\"Func\"] = hmean([result[\"Func\"], result[\"iid score\"]])\n",
    "    result[\"Class\"] = hmean([result[\"Class\"], result[\"iid score\"]])\n",
    "    result[\"Aspect\"] = hmean([result[\"Aspect\"], result[\"iid score\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052eebf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pd.DataFrame()\n",
    "table[[\"Method\", \"Config\"]] = results[0][[\"Method\", \"Config\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3694c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, task in enumerate(tasks):\n",
    "    table[f\"iid score {task}\"] = results[i][\"iid score\"]\n",
    "for i, task in enumerate(tasks):\n",
    "    table[[f\"Seen {task}\", f\"Func {task}\", f\"Class {task}\", f\"Aspect {task}\"]] = results[i][[\"Seen\", \"Func\", \"Class\", \"Aspect\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3156295",
   "metadata": {},
   "outputs": [],
   "source": [
    "table[\"Avg\"] = table.iloc[:,5:].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f18b7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = table.set_index([\"Config\", \"Method\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde0e1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_pvalues = pd.read_csv(\"./data/dataset_pvalues.csv\", index_col=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985e8b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "suite_pvalues = pd.read_csv(\"./data/pvalues_suite_avg.csv\", index_col=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c712eb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "pvalues = pd.concat([dataset_pvalues, suite_pvalues], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7523dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "significant = pvalues < .05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa55390d",
   "metadata": {},
   "outputs": [],
   "source": [
    "significant.loc[(\"iid\")] = 16 * [False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db6b7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = significant.index.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc873c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "order = [idxs[-1]] + idxs[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf53623",
   "metadata": {},
   "outputs": [],
   "source": [
    "significant = significant.reindex(order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb4ca78",
   "metadata": {},
   "outputs": [],
   "source": [
    "significant.index = table.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2dd44ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "significant.columns = table.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6efa707",
   "metadata": {},
   "outputs": [],
   "source": [
    "significant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a8b722",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = table.style.highlight_max(axis=0,\n",
    "                           props='textbf:--rwrap;')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab04c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = l.format(precision=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1b8c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_values(df, significant):\n",
    "    better = \"textcolor: {PineGreen} --rwrap;\"\n",
    "    worse = \"textcolor: {red} --rwrap;\"\n",
    "    same = '' \n",
    "    df1 =  pd.DataFrame(same, index=df.index, columns=df.columns)\n",
    "    b = df >= df.iloc[0]\n",
    "    w = df< df.iloc[0]\n",
    "    return df1.mask(b, better).mask(w, worse).mask(~significant, same)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1582c8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "color = partial(color_values, significant=significant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cd004d",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = l.apply(color, axis=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4f430b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(l.to_latex(multirow_align=\"t\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "checking-checkList",
   "language": "python",
   "name": "checking-checklist"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
